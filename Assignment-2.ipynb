{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will connect to webdriver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the webpage with webdriver\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding elements for search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys('Data Analyst')\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We will create four empty list to store the scrap data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "comapany_name=[]\n",
    "exp_req=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will extract all the datas having job_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will extract all the text from the above tags and store it  in above empty list through for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Engineer/Data Analyst- Chennai',\n",
       " 'Azure Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Executive - Data Analyst']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in title_tag:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "job_title[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the above steps for job_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tag=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hyderabad/Secunderabad, Pune, Chennai, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Devalapur)',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_location=[]\n",
    "for i in location_tag:\n",
    "    loc=i.text\n",
    "    job_location.append(loc)\n",
    "job_location[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the above steps for company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_tag=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inflexion Analytix Private Limited',\n",
       " 'Capgemini Technology Services India Limited',\n",
       " 'Super India Tech Mark',\n",
       " 'Flipkart Internet Private Limited']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in comp_tag:\n",
    "    comp=i.text\n",
    "    comapany_name.append(comp)\n",
    "comapany_name[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will repeat the above steps for experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_tag=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-2 Yrs', '6-8 Yrs', '0-2 Yrs', '1-3 Yrs']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in exp_tag:\n",
    "    exp=i.text\n",
    "    exp_req.append(exp)\n",
    "exp_req[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the length of all four lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(comapany_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will taken all the datas from the lists to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "job=pd.DataFrame({})\n",
    "job['Title']=job_title[0:10]\n",
    "job['Location']=job_location[0:10]\n",
    "job['Company_Name']=comapany_name[0:10]\n",
    "job['Experience']=exp_req[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer/Data Analyst- Chennai</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Azure Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Capgemini Technology Services India Limited</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Devalapur)</td>\n",
       "      <td>Super India Tech Mark</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Executive - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CONDUENT BUSINESS SERVICES INDIA LLP</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - Alteryx, Tableau and SQL</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title  \\\n",
       "0      Data Engineer/Data Analyst- Chennai   \n",
       "1                       Azure Data Analyst   \n",
       "2                             Data Analyst   \n",
       "3                 Executive - Data Analyst   \n",
       "4                             Data Analyst   \n",
       "5  Data Analyst - Alteryx, Tableau and SQL   \n",
       "6                             Data Analyst   \n",
       "7                             Data Analyst   \n",
       "8                             Data Analyst   \n",
       "9                             Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                     Bangalore/Bengaluru(Devalapur)   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                  Company_Name Experience  \n",
       "0           Inflexion Analytix Private Limited    0-2 Yrs  \n",
       "1  Capgemini Technology Services India Limited    6-8 Yrs  \n",
       "2                        Super India Tech Mark    0-2 Yrs  \n",
       "3            Flipkart Internet Private Limited    1-3 Yrs  \n",
       "4         CONDUENT BUSINESS SERVICES INDIA LLP    1-2 Yrs  \n",
       "5                           Schneider Electric    2-5 Yrs  \n",
       "6                     Myntra Designs Pvt. Ltd.    3-6 Yrs  \n",
       "7                     Myntra Designs Pvt. Ltd.    4-8 Yrs  \n",
       "8                     Myntra Designs Pvt. Ltd.    3-8 Yrs  \n",
       "9                     Myntra Designs Pvt. Ltd.    4-8 Yrs  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in \n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting to webdriver and getting webpage through it.\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding elements for search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys('Banglore')\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create four empty lists to store the scrapped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_title=[]\n",
    "j_loc=[]\n",
    "c_name=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will extract all the tags for job_title and store it in j_title list as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Data Scientist - Machine Learning',\n",
       " 'Data Scientist - IBM Garage',\n",
       " 'GAMMA Lead Data Scientist']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag=driver.find_elements_by_xpath(\"//a[@class=('title fw500 ellipsis')]\")\n",
    "for i in title_tag:\n",
    "    j_title.append(i.text)\n",
    "j_title[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will follow the above steps for job_location and company_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru',\n",
       " 'Mumbai, New Delhi, Chennai, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_tag=driver.find_elements_by_xpath(\"//ul[@class=('mt-7')]/li[3]\")\n",
    "for i in loc_tag:\n",
    "    j_loc.append(i.text)\n",
    "j_loc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CronJ IT Technologies Private Limited',\n",
       " 'AugmatrixGo',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Boston Consulting Group']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_tag=driver.find_elements_by_xpath(\"//a[@class=('subTitle ellipsis fleft')]\")\n",
    "for i in c_tag:\n",
    "    c_name.append(i.text)\n",
    "c_name[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(j_title),len(j_loc),len(c_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All list have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will taken all the datas from the lists to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=pd.DataFrame({})\n",
    "job['Title']=j_title[0:10]\n",
    "job['Location']=j_loc[0:10]\n",
    "job['Company_Name']=c_name[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>CronJ IT Technologies Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GAMMA Lead Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBCG IND - GAMMA Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>GANIT BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric India Pvt. Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Scientist - CRM &amp; Loyalty</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Business Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Philips India Limited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                  Data Scientist - Machine Learning   \n",
       "2                        Data Scientist - IBM Garage   \n",
       "3                          GAMMA Lead Data Scientist   \n",
       "4             DBCG IND - GAMMA Senior Data Scientist   \n",
       "5               Data Scientist/Senior Data Scientist   \n",
       "6  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "7                                     Data Scientist   \n",
       "8           Associate Data Scientist - CRM & Loyalty   \n",
       "9                Data Scientist - Business Analytics   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "3    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "4    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru   \n",
       "5  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "6  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                               Company_Name  \n",
       "0     CronJ IT Technologies Private Limited  \n",
       "1                               AugmatrixGo  \n",
       "2                    IBM India Pvt. Limited  \n",
       "3                   Boston Consulting Group  \n",
       "4                   Boston Consulting Group  \n",
       "5  GANIT BUSINESS SOLUTIONS PRIVATE LIMITED  \n",
       "6                                  CES Ltd.  \n",
       "7        Schneider Electric India Pvt. Ltd.  \n",
       "8       Shell India Markets Private Limited  \n",
       "9                     Philips India Limited  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the \n",
    "webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field \n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done \n",
    "manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with webdriver and opening webpage with it.\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching the elements\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using filter\n",
    "loc=driver.find_elements_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[1]/p[1]/span[1]\")\n",
    "for i in loc:\n",
    "    if i.text=='Delhi / NCR':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal=driver.find_elements_by_xpath(\"//div[@class='mt-8 chckBoxCont']/label[1]/p[1]/span[1]\")\n",
    "for i in sal:\n",
    "    if i.text=='3-6 Lakhs':\n",
    "        i.click()\n",
    "        break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty list for storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "comapany_name=[]\n",
    "exp_req=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from respective tags and appending it in repective lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tag:\n",
    "    job_title.append(i.text)\n",
    "comp_tag=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for j in comp_tag:\n",
    "    comapany_name.append(j.text)\n",
    "loc_tag=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[3]/span\")\n",
    "for k in loc_tag:\n",
    "    job_location.append(k.text)\n",
    "exp_tag=driver.find_elements_by_xpath(\"//ul[@class='mt-7']/li[1]/span\")\n",
    "for l in exp_tag:\n",
    "    exp_req.append(l.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(comapany_name),len(exp_req))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All lists have the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will taken all the datas from the lists to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "job=pd.DataFrame({})\n",
    "job['Title']=job_title[0:10]\n",
    "job['Location']=job_location[0:10]\n",
    "job['Company_Name']=comapany_name[0:10]\n",
    "job['Experience']=exp_req[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Females Required- Data Scientist- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Randstad</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Hadoop/BigQuery</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Jubna</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Python &amp; Machine Learning</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Required- Data Scientist (NLP)-Axis Bank - 6 m...</td>\n",
       "      <td>Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...</td>\n",
       "      <td>Axis Bank Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Python / Machine Learning / T...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>FUTURES AND CAREERS</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                        Data Scientist - IBM Garage   \n",
       "1            Females Required- Data Scientist- Noida   \n",
       "2         Data Scientist - Python & Machine Learning   \n",
       "3         Data Scientist - Python & Machine Learning   \n",
       "4  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "5                   Data Scientist - Hadoop/BigQuery   \n",
       "6  Data Scientist - Python / Machine Learning / T...   \n",
       "7         Data Scientist - Python & Machine Learning   \n",
       "8  Required- Data Scientist (NLP)-Axis Bank - 6 m...   \n",
       "9  Data Scientist - Python / Machine Learning / T...   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "1               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "2  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "3  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "4               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "5                                              Noida   \n",
       "6  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "7  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "8  Kolkata, New Delhi, Hyderabad/Secunderabad, Pu...   \n",
       "9  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "\n",
       "                Company_Name Experience  \n",
       "0     IBM India Pvt. Limited    5-8 Yrs  \n",
       "1                   Randstad    3-7 Yrs  \n",
       "2        FUTURES AND CAREERS    2-7 Yrs  \n",
       "3        FUTURES AND CAREERS    2-7 Yrs  \n",
       "4  GABA Consultancy services    0-5 Yrs  \n",
       "5                      Jubna    3-6 Yrs  \n",
       "6        FUTURES AND CAREERS    3-8 Yrs  \n",
       "7        FUTURES AND CAREERS    2-7 Yrs  \n",
       "8          Axis Bank Limited    4-9 Yrs  \n",
       "9        FUTURES AND CAREERS    3-8 Yrs  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist \n",
    "Designation in Noida location. You have to scrape company_name, No. of days \n",
    "ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” \n",
    "in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown \n",
    "page.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done \n",
    "manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to webdriver and get website throught it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get('https://www.glassdoor.co.in/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding element for serach bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_id(\"sc.keyword\")\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc=driver.find_element_by_id(\"sc.location\")\n",
    "search_loc.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists for storing data from tags as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_posted=[]\n",
    "company_name=[]\n",
    "rating=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from respective tags and appending it in repective lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tag=driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column pl-sm css-1d3xmk8 e1rrn5ka4']/div[1]/a[1]\")\n",
    "for i in title_tag:\n",
    "    company_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_tag=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between css-1qtdns2']/div[2]\")\n",
    "for j in days_tag:\n",
    "    days_posted.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tag=driver.find_elements_by_xpath(\"//div[@class='d-flex flex-column css-x75kgh e1rrn5ka3']/span\")\n",
    "for k in rating_tag:\n",
    "    rating.append(k.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the length of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 18\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name),len(days_posted),len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since all entries do not have rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "job2=pd.DataFrame({})\n",
    "job2['Company_Name']=company_name[0:10]\n",
    "job2['No. of days ago']=days_posted[0:10]\n",
    "job2['Rating']=rating[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>No. of days ago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unyscape Infocom Pvt. Ltd</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>30d+</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>13d</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>30d+</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aedifico Tech</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>30d+</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree Analytics And Services</td>\n",
       "      <td>5d</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EMVEE Information Technologies Private Limited</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Company_Name No. of days ago Rating\n",
       "0                       Unyscape Infocom Pvt. Ltd             24h    4.1\n",
       "1                                  Biz2Credit Inc            30d+    3.8\n",
       "2                    Salasar New Age Technologies            30d+    4.4\n",
       "3                                           Adobe             13d    5.0\n",
       "4                                        Techlive            30d+    4.0\n",
       "5                    Salasar New Age Technologies            30d+    5.0\n",
       "6                                   Aedifico Tech            30d+    4.0\n",
       "7                                 SearchUrCollege            30d+    4.4\n",
       "8            Decision Tree Analytics And Services              5d    5.0\n",
       "9  EMVEE Information Technologies Private Limited             24h    3.8"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation \n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company \n",
    "name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to webdriver and getting website through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(' https://www.glassdoor.co.in/Salaries/index.htm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding element for search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job=driver.find_element_by_xpath(\"//input[@class='keyword']\")\n",
    "search_job.send_keys('Data Scientist')\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@class='loc']\")\n",
    "search_loc.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-btn-mkt']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists to store data from tags in text form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_name=[]\n",
    "no_sal=[]\n",
    "avg_sal=[]\n",
    "min_sal=[]\n",
    "max_sal=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from respective tags and append then to above empty list respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tata Consultancy Services', 'Accenture', 'Delhivery', 'IBM']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cname_tag=driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[2]\")\n",
    "for i in cname_tag:\n",
    "    comp_name.append(i.text)\n",
    "comp_name[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14 salaries', '14 salaries', '14 salaries', '13 salaries']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sal_tag=driver.find_elements_by_xpath(\"//div[@class='d-flex']/div[2]/p[5]\")\n",
    "for i in sal_tag:\n",
    "    no_sal.append(i.text)\n",
    "no_sal[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹ 5,97,967/yr', '₹ 11,12,243/yr', '₹ 12,12,741/yr', '₹ 7,37,972/yr']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_tag=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']\")\n",
    "for i in avg_tag:\n",
    "    avg_sal.append(i.text.replace('\\n',''))\n",
    "avg_sal[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹333K', '₹560K', '₹436K', '₹569K']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_tag=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[1]\")\n",
    "for i in min_tag:\n",
    "    min_sal.append(i.text)\n",
    "min_sal[0:4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹1,080K', '₹2,147K', '₹11,274K', '₹2,648K']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tag=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "for i in max_tag:\n",
    "    max_sal.append(i.text)\n",
    "max_sal[0:4] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(comp_name),len(no_sal),len(avg_sal),len(min_sal),len(max_sal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All lists have have length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=pd.DataFrame({})\n",
    "job['Company_Name']=comp_name[0:10]\n",
    "job['No. of Salaries']=no_sal[0:10]\n",
    "job['Average_Salary ']=avg_sal[0:10]\n",
    "job['Minimum_Salary']=min_sal[0:10]\n",
    "job['Maximum_Salary']=max_sal[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>No. of Salaries</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Minimum_Salary</th>\n",
       "      <th>Maximum_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 5,97,967/yr</td>\n",
       "      <td>₹333K</td>\n",
       "      <td>₹1,080K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 11,12,243/yr</td>\n",
       "      <td>₹560K</td>\n",
       "      <td>₹2,147K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹ 12,12,741/yr</td>\n",
       "      <td>₹436K</td>\n",
       "      <td>₹11,274K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IBM</td>\n",
       "      <td>13 salaries</td>\n",
       "      <td>₹ 7,37,972/yr</td>\n",
       "      <td>₹569K</td>\n",
       "      <td>₹2,648K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>12 salaries</td>\n",
       "      <td>₹ 7,15,984/yr</td>\n",
       "      <td>₹350K</td>\n",
       "      <td>₹1,565K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹ 13,41,900/yr</td>\n",
       "      <td>₹1,037K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹ 7,90,812/yr</td>\n",
       "      <td>₹487K</td>\n",
       "      <td>₹1,421K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Innovaccer</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹ 11,81,047/yr</td>\n",
       "      <td>₹602K</td>\n",
       "      <td>₹1,644K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 9,89,924/yr</td>\n",
       "      <td>₹196K</td>\n",
       "      <td>₹1,755K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹ 11,73,127/yr</td>\n",
       "      <td>₹558K</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company_Name No. of Salaries Average_Salary  Minimum_Salary  \\\n",
       "0  Tata Consultancy Services     14 salaries   ₹ 5,97,967/yr          ₹333K   \n",
       "1                  Accenture     14 salaries  ₹ 11,12,243/yr          ₹560K   \n",
       "2                  Delhivery     14 salaries  ₹ 12,12,741/yr          ₹436K   \n",
       "3                        IBM     13 salaries   ₹ 7,37,972/yr          ₹569K   \n",
       "4         Ericsson-Worldwide     12 salaries   ₹ 7,15,984/yr          ₹350K   \n",
       "5         UnitedHealth Group     10 salaries  ₹ 13,41,900/yr        ₹1,037K   \n",
       "6         Valiance Solutions      9 salaries   ₹ 7,90,812/yr          ₹487K   \n",
       "7                 Innovaccer      8 salaries  ₹ 11,81,047/yr          ₹602K   \n",
       "8              ZS Associates      7 salaries   ₹ 9,89,924/yr          ₹196K   \n",
       "9                EXL Service      7 salaries  ₹ 11,73,127/yr          ₹558K   \n",
       "\n",
       "  Maximum_Salary  \n",
       "0        ₹1,080K  \n",
       "1        ₹2,147K  \n",
       "2       ₹11,274K  \n",
       "3        ₹2,648K  \n",
       "4        ₹1,565K  \n",
       "5        ₹1,500K  \n",
       "6        ₹1,421K  \n",
       "7        ₹1,644K  \n",
       "8        ₹1,755K  \n",
       "9        ₹1,500K  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to \n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and \n",
    "more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page \n",
    "you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of \n",
    "the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to webdriver and getting the website through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(' https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching element for search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pro=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_pro.send_keys('sunglasses')\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists to store data from tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "prod_descrip=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting URLs of page 1,2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "URL=[]\n",
    "for i in urls[0:3]:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from respective tag from all the three pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in URL:\n",
    "    driver.get(url)\n",
    "    bd=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/div[1]\")\n",
    "    for i in bd:\n",
    "        brand.append(i.text)\n",
    "    pd=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "    for i in pd:\n",
    "        prod_descrip.append(i.text)\n",
    "    pr=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div[1]/div[1]\")\n",
    "    for i in pr:\n",
    "        price.append(i.text)\n",
    "    dis=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div[1]/div[3]\")\n",
    "    for i in dis:\n",
    "        discount.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(brand),len(prod_descrip),len(price),len(discount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the lists have equal length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending the data to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sunglass=pd.DataFrame({})\n",
    "sunglass['BRAND']=brand[0:100]\n",
    "sunglass['Product_Description']=prod_descrip[0:100]\n",
    "sunglass['PRICE']=price[0:100]\n",
    "sunglass['DISCOUNT']=discount[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹426</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Over-sized Sunglasses (60)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹683</td>\n",
       "      <td>24% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹187</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹469</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (54)</td>\n",
       "      <td>₹559</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (55)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Gradient, Night Vision, Mirrore...</td>\n",
       "      <td>₹295</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Gradient Cat-eye Sunglasses (63)</td>\n",
       "      <td>₹296</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             BRAND                                Product_Description PRICE  \\\n",
       "0   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹426   \n",
       "1           PIRASO           UV Protection Over-sized Sunglasses (60)  ₹179   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹683   \n",
       "3           PIRASO              UV Protection Aviator Sunglasses (54)  ₹187   \n",
       "4         Fastrack  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹469   \n",
       "..             ...                                                ...   ...   \n",
       "95        Fastrack             UV Protection Wayfarer Sunglasses (54)  ₹559   \n",
       "96       ROYAL SON             UV Protection Wayfarer Sunglasses (55)  ₹237   \n",
       "97  ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹404   \n",
       "98           NuVew  UV Protection, Gradient, Night Vision, Mirrore...  ₹295   \n",
       "99           NuVew    UV Protection, Gradient Cat-eye Sunglasses (63)  ₹296   \n",
       "\n",
       "   DISCOUNT  \n",
       "0   88% off  \n",
       "1   88% off  \n",
       "2   24% off  \n",
       "3   88% off  \n",
       "4   53% off  \n",
       "..      ...  \n",
       "95  37% off  \n",
       "96  81% off  \n",
       "97  79% off  \n",
       "98  70% off  \n",
       "99  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to \n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes\u0002earpods-power\u0002adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage.\n",
    "As shown in the above page you have to scrape the tick marked attributes.\n",
    "These are \n",
    "1. Rating \n",
    "2. Review_summary \n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting webdriver and getting the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening all the review by clicking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_rev=driver.find_element_by_xpath(\"//div[@class='col JOpGWq']/a\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting urls of 10 pages and string it in URL list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=driver.find_elements_by_xpath(\"//nav[@class=('yFHi8N')]/a\")\n",
    "URL=[]\n",
    "for i in urls:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=[]\n",
    "rev_sum=[]\n",
    "ful_rev=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from all 10 pages and storing data from respective tags to their respective lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in URL[0:10]:\n",
    "    driver.get(url)\n",
    "    rat=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "    for i in rat:\n",
    "        rating.append(i.text)\n",
    "    r_sum=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/p[1]\")\n",
    "    for j in r_sum:\n",
    "        rev_sum.append(j.text)\n",
    "    f_rev=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[2]\")\n",
    "    for k in f_rev:\n",
    "        ful_rev.append(k.text)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating),len(rev_sum),len(ful_rev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All lists have same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing data from lists to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "review=pd.DataFrame({})\n",
    "review['Rating']=rating[:]\n",
    "review['Review_Summary']=rev_sum[:]\n",
    "review['Full_Review']=ful_rev[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Everything is perfect pictures come out so cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>I got this beast today. And I must say the pic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>iPhone is delivered on time. Display is great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>I will just say its an awesome phone. Starting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_Summary  \\\n",
       "0       5           Brilliant   \n",
       "1       5    Perfect product!   \n",
       "2       5   Worth every penny   \n",
       "3       5       Great product   \n",
       "4       5  Highly recommended   \n",
       "..    ...                 ...   \n",
       "95      5           Fabulous!   \n",
       "96      5           Wonderful   \n",
       "97      5            Terrific   \n",
       "98      5   Worth every penny   \n",
       "99      5           Must buy!   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Previously I was using one plus 3t it was a gr...  \n",
       "3   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "4   iphone 11 is a very good phone to buy only if ...  \n",
       "..                                                ...  \n",
       "95  Everything is perfect pictures come out so cle...  \n",
       "96  Nice value for money good and best price I pho...  \n",
       "97  I got this beast today. And I must say the pic...  \n",
       "98  iPhone is delivered on time. Display is great ...  \n",
       "99  I will just say its an awesome phone. Starting...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and \n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Also note that all the steps required during scraping should be done through code \n",
    "only and not manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting webdriver and getting website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(' https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching element for search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sneaker=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_sneaker.send_keys('sneakers')\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exracting urls from all pages and storing in URL lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "URL=[]\n",
    "for i in urls:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND=[]\n",
    "pro_descrip=[]\n",
    "PRICE=[]\n",
    "DISCOUNT=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from first 3 pages and storing data from respecting tags in text form to respective lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in URL[0:3]:\n",
    "    driver.get(url)\n",
    "    bd=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/div[1]\")\n",
    "    for i in bd:\n",
    "        BRAND.append(i.text)\n",
    "    pd=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "    for i in pd:\n",
    "        pro_descrip.append(i.text)\n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div[1]/div[1]\")\n",
    "    for i in price:\n",
    "        PRICE.append(i.text)\n",
    "    discount=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[2]/div[1]/div[3]\")\n",
    "    for i in discount:\n",
    "        DISCOUNT.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 118\n"
     ]
    }
   ],
   "source": [
    "print(len(BRAND),len(pro_descrip),len(PRICE),len(DISCOUNT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some items do not have discounts , so length of DISCOUNT is less than other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sneakers=pd.DataFrame({})\n",
    "sneakers['BRAND']=BRAND[0:100]\n",
    "sneakers['Product_Description']=pro_descrip[0:100]\n",
    "sneakers['PRICE']=PRICE[0:100]\n",
    "sneakers['DISCOUNT']=DISCOUNT[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>DISCOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>French Connection</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹680</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Men's Combo Pack of 02 Shoes for Men Casual Sn...</td>\n",
       "      <td>₹420</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Perfect &amp; Affordable Combo Pack of 02 Pairs Sn...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super &amp; Trendy Men's Pack of 02 Pair Shoes for...</td>\n",
       "      <td>₹420</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Latest Collection-349 Stylish Casual Sports Sn...</td>\n",
       "      <td>₹169</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MOU</td>\n",
       "      <td>Zar Check Sneakers Sneakers For Men</td>\n",
       "      <td>₹529</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹451</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Men's Combo Pack of 02 Shoes for Men Casual Sn...</td>\n",
       "      <td>₹420</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  BRAND                                Product_Description  \\\n",
       "0     French Connection                                   Sneakers For Men   \n",
       "1                Chevit  Men's Combo Pack of 02 Shoes for Men Casual Sn...   \n",
       "2                Chevit  Perfect & Affordable Combo Pack of 02 Pairs Sn...   \n",
       "3          Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "4                Chevit  Super & Trendy Men's Pack of 02 Pair Shoes for...   \n",
       "..                  ...                                                ...   \n",
       "95  World Wear Footwear  Latest Collection-349 Stylish Casual Sports Sn...   \n",
       "96            ROCKFIELD                                   Sneakers For Men   \n",
       "97                  MOU                Zar Check Sneakers Sneakers For Men   \n",
       "98         Robbie jones                                   Sneakers For Men   \n",
       "99               Chevit  Men's Combo Pack of 02 Shoes for Men Casual Sn...   \n",
       "\n",
       "   PRICE DISCOUNT  \n",
       "0   ₹680  65% off  \n",
       "1   ₹420  57% off  \n",
       "2   ₹499  72% off  \n",
       "3   ₹379  62% off  \n",
       "4   ₹420  78% off  \n",
       "..   ...      ...  \n",
       "95  ₹169  47% off  \n",
       "96  ₹379  54% off  \n",
       "97  ₹529  57% off  \n",
       "98  ₹451  58% off  \n",
       "99  ₹420  65% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in \n",
    "the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of \n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be \n",
    "done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting webdriver and getting website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(' https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_2=driver.find_elements_by_xpath(\"//li[@class='colour-listItem']\")\n",
    "for j in filter_2:\n",
    "    if j.text=='Black (17162)':\n",
    "        j.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1=driver.find_elements_by_xpath(\"//ul[@class='price-list']/li\")\n",
    "for i in filter_1:\n",
    "    if i.text=='Rs. 6657 to Rs. 13105(612)':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAND=[]\n",
    "Descrip=[]\n",
    "PRICE=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting urls of all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=driver.find_elements_by_xpath(\"//ul[@class='pagination-container']/li/a\")\n",
    "URL=[]\n",
    "for i in url:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting data from two pages and storing in repecting lists from extracting from respecting tags in text form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in URL[0:2]:\n",
    "    driver.get(i)\n",
    "    bd=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for i in bd:\n",
    "        BRAND.append(i.text)\n",
    "    des=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    for i in des:\n",
    "        Descrip.append(i.text)\n",
    "    price=driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]/span[1]\")\n",
    "    for i in price:\n",
    "        PRICE.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking length of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 41\n"
     ]
    }
   ],
   "source": [
    "print(len(BRAND),len(Descrip),len(PRICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is an expection, as item where there is no discount mention, can't scrap it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneaker2=pd.DataFrame({})\n",
    "sneaker2['BRAND']=BRAND[0:40]\n",
    "sneaker2['DESCRIPTION']=Descrip[0:40]\n",
    "sneaker2['PRICE']=PRICE[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRAND</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 10121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>Rs. 10846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT MILER Running Shoes</td>\n",
       "      <td>Rs. 8246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex Mercedes Running Shoes</td>\n",
       "      <td>Rs. 7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 6996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 10496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nike</td>\n",
       "      <td>AIR ZOOM PEGASUS Running Shoes</td>\n",
       "      <td>Rs. 8396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women ZOOM SPAN 3 Running</td>\n",
       "      <td>Rs. 7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JOYRIDE Running Shoes</td>\n",
       "      <td>Rs. 10121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT Running Shoes</td>\n",
       "      <td>Rs. 7149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD13 EP Basketball Shoes</td>\n",
       "      <td>Rs. 7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Mesh Fuse Training Or Gym Shoes</td>\n",
       "      <td>Rs. 7693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men VIPER COMPETITOR Training</td>\n",
       "      <td>Rs. 9443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women REACT ESCAPE Running</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women UNO Sneakers</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women AIR ZOOM Running</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Textured Leather Formal Loafers</td>\n",
       "      <td>Rs. 9349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro Running</td>\n",
       "      <td>Rs. 6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Guardian 2 Sports Shoes</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Sonic 3 Running Shoes</td>\n",
       "      <td>Rs. 6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR STRT Sportstyle Shoes</td>\n",
       "      <td>Rs. 6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Liquify Rebel Running</td>\n",
       "      <td>Rs. 7440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>Rs. 7117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women TriBase Reign 2 Training</td>\n",
       "      <td>Rs. 7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>HOVR Sonic 3 Running Shoes</td>\n",
       "      <td>Rs. 8992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Formal Derbys</td>\n",
       "      <td>Rs. 7117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Liberate Nitro Running</td>\n",
       "      <td>Rs. 9793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women HOVR Rise 2 Training</td>\n",
       "      <td>Rs. 7192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Liquify Running Shoes</td>\n",
       "      <td>Rs. 6749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women D'LITES 3.0 Sneakers</td>\n",
       "      <td>Rs. 7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breathe TR 2</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 11242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 9742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Impulse Running Shoes</td>\n",
       "      <td>Rs. 7867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Puma</td>\n",
       "      <td>SPEED Orbiter Running Shoes</td>\n",
       "      <td>Rs. 9367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BRAND                          DESCRIPTION      PRICE\n",
       "0              Nike           Men AIR ZOOM Running Shoes  Rs. 10121\n",
       "1              ALDO                  Men Leather Loafers   Rs. 7799\n",
       "2              Nike           Men React Infinity Running  Rs. 10846\n",
       "3              Nike        Men REACT MILER Running Shoes   Rs. 8246\n",
       "4   PUMA Motorsport        Unisex Mercedes Running Shoes   Rs. 7197\n",
       "5              Nike                  Women Running Shoes   Rs. 6996\n",
       "6              Nike         Women AIR ZOOM Running Shoes  Rs. 10496\n",
       "7              Nike       AIR ZOOM PEGASUS Running Shoes   Rs. 8396\n",
       "8              Nike            Women ZOOM SPAN 3 Running   Rs. 7721\n",
       "9              Nike            Men JOYRIDE Running Shoes  Rs. 10121\n",
       "10             Nike            Women REACT Running Shoes   Rs. 7149\n",
       "11             Nike          Men JORDAN DELTA Basketball   Rs. 7499\n",
       "12             Nike         Men KD13 EP Basketball Shoes   Rs. 7492\n",
       "13             Puma  Men Mesh Fuse Training Or Gym Shoes   Rs. 7693\n",
       "14         Skechers        Men VIPER COMPETITOR Training   Rs. 9443\n",
       "15             Nike         Women AIR ZOOM Running Shoes   Rs. 7499\n",
       "16             Nike           Women REACT ESCAPE Running   Rs. 8499\n",
       "17         Skechers                   Women UNO Sneakers   Rs. 6993\n",
       "18             Nike               Women AIR ZOOM Running   Rs. 7499\n",
       "19          Bugatti  Men Textured Leather Formal Loafers   Rs. 9349\n",
       "20             Puma           Men Velocity Nitro Running   Rs. 6749\n",
       "21     Hush Puppies    Men Solid Leather Formal Slip-Ons   Rs. 7039\n",
       "22     UNDER ARMOUR         HOVR Guardian 2 Sports Shoes   Rs. 6993\n",
       "23     UNDER ARMOUR           HOVR Sonic 3 Running Shoes   Rs. 6993\n",
       "24     UNDER ARMOUR       Men HOVR STRT Sportstyle Shoes   Rs. 6675\n",
       "25     UNDER ARMOUR          Women Liquify Rebel Running   Rs. 7440\n",
       "26             Nike            Men JORDAN DELTA Sneakers   Rs. 7117\n",
       "27             Puma                    Men Running Shoes  Rs. 11999\n",
       "28     UNDER ARMOUR       Women TriBase Reign 2 Training   Rs. 7192\n",
       "29     UNDER ARMOUR           HOVR Sonic 3 Running Shoes   Rs. 8992\n",
       "30     Hush Puppies                    Men Formal Derbys   Rs. 7117\n",
       "31             Puma           Men Liberate Nitro Running   Rs. 9793\n",
       "32     UNDER ARMOUR           Women HOVR Rise 2 Training   Rs. 7192\n",
       "33     UNDER ARMOUR            Men Liquify Running Shoes   Rs. 6749\n",
       "34         Skechers           Women D'LITES 3.0 Sneakers   Rs. 7492\n",
       "35     UNDER ARMOUR           Women Charged Breathe TR 2   Rs. 7499\n",
       "36             Puma                    Men Running Shoes  Rs. 11242\n",
       "37          Bugatti      Men Solid Leather Formal Derbys   Rs. 9742\n",
       "38     UNDER ARMOUR        Charged Impulse Running Shoes   Rs. 7867\n",
       "39             Puma          SPEED Orbiter Running Shoes   Rs. 9367"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneaker2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the \n",
    "below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes \n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting webdriver and getting webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r'C:\\Users\\Nitin Singh Tatrari\\Downloads\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding elements for search tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_lap=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_lap.send_keys('Laptop')\n",
    "search_button=driver.find_element_by_id(\"nav-search-submit-button\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_1:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_2=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_2:\n",
    "    if i.text=='Intel Core i9':\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating empty lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE=[]\n",
    "RATING=[]\n",
    "PRICE=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a/span\")\n",
    "for i in title:\n",
    "    TITLE.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 14-inch FHD IPS 2-in-1 Touchscreen Laptop (16GB/512GB SSD/Win 10/Office 2019/Lenovo Digital Pen Stylus/Fingerprint Reader/Graphite Grey/1.5Kg), 82HS0092IN',\n",
       " 'ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11th Gen 14-inch FHD Thin and Light Laptop (16GB RAM/512GB NVMe SSD/Windows 10/MS Office 2019/Intel Iris Xᵉ Graphics/Pine Grey/1.17 kg), UX425EA-BM701TS',\n",
       " 'HP 14 Thin & Light 14-inch FHD Laptop (11th Gen Intel i7-1165G7/8GB/512GB SSD/Windows 10/MS Office 2019/Alexa Built-in/Pale Gold/1.47 kg), 14s-dr2007TU',\n",
       " 'Dell Alienware m15(R3) 15.6-inch FHD Gaming Laptop (10th Gen Core i7-10750H/16GB/512GB SSD/Windows 10 Home & MS Office/6GB NVIDIA GTX 1660 Ti Graphics), Lunar Light']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TITLE[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['86,690', '95,993', '76,500', '1,98,590']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in price:\n",
    "    PRICE.append(i.text)\n",
    "PRICE[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-beside-button a-text-bold']\")\n",
    "for i in rating:\n",
    "    RATING.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RATING[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not able to scrap rating, Thus we will leave it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 25\n"
     ]
    }
   ],
   "source": [
    "print(len(TITLE),len(PRICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop=pd.DataFrame({})\n",
    "Laptop['TITLE']=TITLE[0:10]\n",
    "Laptop['PRICE']=PRICE[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>86,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>95,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>76,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>1,98,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>53,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...</td>\n",
       "      <td>5,22,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...</td>\n",
       "      <td>1,35,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...</td>\n",
       "      <td>47,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>2,77,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>95,993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE     PRICE\n",
       "0  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...    86,690\n",
       "1  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...    95,993\n",
       "2  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...    76,500\n",
       "3  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...  1,98,590\n",
       "4  Mi Notebook Horizon Edition 14 Intel Core i5-1...    53,999\n",
       "5  ASUS ROG G703GI-E5148T 17.3-inch FHD 144Hz/3ms...  5,22,077\n",
       "6  Lenovo Legion 5Pi 10th Gen Intel Core i7 15.6\"...  1,35,490\n",
       "7  (Renewed) Lenovo Thinkpad Yoga S1 Laptop (CORE...    47,190\n",
       "8  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  2,77,390\n",
       "9  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...    95,993"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
